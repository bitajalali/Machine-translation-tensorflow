{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb","timestamp":1580864385977}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EbAG2kPQ2bxt","outputId":"06d5e48c-5f06-4a5b-ab0e-91a1da12ef75","executionInfo":{"status":"ok","timestamp":1581131095860,"user_tz":-210,"elapsed":16307,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"source":["# !wget http://www.manythings.org/anki/deu-eng.zip\n","# !unzip /content/deu-eng.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-02-08 03:04:44--  http://www.manythings.org/anki/deu-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:3037::6818:6cc4, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7747747 (7.4M) [application/zip]\n","Saving to: ‘deu-eng.zip’\n","\n","\rdeu-eng.zip           0%[                    ]       0  --.-KB/s               \rdeu-eng.zip          22%[===>                ]   1.63M  8.12MB/s               \rdeu-eng.zip         100%[===================>]   7.39M  23.3MB/s    in 0.3s    \n","\n","2020-02-08 03:04:44 (23.3 MB/s) - ‘deu-eng.zip’ saved [7747747/7747747]\n","\n","Archive:  /content/deu-eng.zip\n","  inflating: deu.txt                 \n","  inflating: _about.txt              \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tnxXKDjq3jEL","outputId":"17758c3b-d33c-486b-811e-f4d0e8ecde32","executionInfo":{"status":"ok","timestamp":1581131197303,"user_tz":-210,"elapsed":9882,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cnt85HhF3vIK"},"source":["path_to_file = \"/content/deu.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rd0jw-eC3jEh"},"source":["# Converts the unicode file to ascii\n","def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\n","      if unicodedata.category(c) != 'Mn')\n","\n","\n","def preprocess_sentence(w):\n","  w = unicode_to_ascii(w.lower().strip())\n","\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","\n","  w = w.rstrip().strip()\n","\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHn4Dct23jEm"},"source":["# 1. Remove the accents\n","# 2. Clean the sentences\n","# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n","def create_dataset(path, num_examples):\n","  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n","  \n","  return word_pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTbSbBz55QtF","outputId":"f1d211f1-1760-46f5-8043-1162e83f6421","executionInfo":{"status":"ok","timestamp":1581131212565,"user_tz":-210,"elapsed":19561,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["word_pairs = create_dataset(path_to_file, None)\n","en,deu,_ = zip(*word_pairs)\n","print(en[-1])\n","print(deu[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n","<start> ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht , dass ein mensch nur gelegenheit hat , mit ein paar hundert anderen bekannt zu sein , von denen ihm nur ein dutzend oder weniger nahesteht , darunter hochstens ein oder zwei freunde , dann erahnt man eingedenk der millionen einwohner dieser welt leicht , dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist . <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OmMZQpdO60dt"},"source":["def max_length(tensor):\n","  return max(len(t) for t in tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIOn8RCNDJXG"},"source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","\n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                         padding='post')\n","  \n","  return tensor, lang_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAY9k49G3jE_"},"source":["def load_dataset(path, num_examples=None):\n","  # creating cleaned input, output pairs\n","  word_pairs = create_dataset(path, num_examples)\n","  targ_lang, inp_lang,_ = zip(*word_pairs)\n","\n","  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOi42V79Ydlr"},"source":["### Limit the size of the dataset to experiment faster (optional)\n","\n","Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"]},{"cell_type":"code","metadata":{"id":"cnxC7q-j3jFD"},"source":["# Try experimenting with the size of that dataset\n","num_examples = 30000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QILQkOs3jFG","outputId":"bda577a2-e84f-4358-8aa8-3e0d81547544","executionInfo":{"status":"ok","timestamp":1581090676558,"user_tz":-210,"elapsed":21422,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Show length\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24000 24000 6000 6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJPmLZGMeD5q"},"source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t!=0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXukARTDd7MT","outputId":"1b795145-0517-4d20-f7ef-4fc18268c4ed","executionInfo":{"status":"ok","timestamp":1581090676564,"user_tz":-210,"elapsed":21408,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":350}},"source":["print (\"Input Language; index to word mapping\")\n","convert(inp_lang, input_tensor_train[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(targ_lang, target_tensor_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","1 ----> <start>\n","319 ----> bleib\n","12 ----> nicht\n","20 ----> zu\n","444 ----> lange\n","122 ----> weg\n","3 ----> .\n","2 ----> <end>\n","\n","Target Language; index to word mapping\n","1 ----> <start>\n","30 ----> don\n","12 ----> t\n","39 ----> be\n","257 ----> long\n","3 ----> .\n","2 ----> <end>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rgCLkfv5uO3d"},"source":["### Create a tf.data dataset"]},{"cell_type":"code","metadata":{"id":"TqHsArVZ3jFS"},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","input_tensor_train_one_hot = []\n","target_tensor_train_one_hot = []\n","\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qc6-NK1GtWQt","outputId":"de608d4e-abd5-4613-9820-ac534c3e9f6e","executionInfo":{"status":"ok","timestamp":1581090676566,"user_tz":-210,"elapsed":21389,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 14]), TensorShape([64, 10]))"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"nZ2rI24i3jFg"},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.vocab_size = vocab_size\n","    # self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    # x = self.embedding(x)\n","    \n","    x_one_hot = []\n","    for i in x:\n","      x_one_hot.append(tf.keras.utils.to_categorical(i,self.vocab_size))\n","    x = np.asarray(x_one_hot)\n","    output, state = self.gru(x, initial_state = hidden)\n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60gSVh05Jl6l","outputId":"dbbe66f7-6fee-45b9-c900-2c9dfd822ea8","executionInfo":{"status":"ok","timestamp":1581090850122,"user_tz":-210,"elapsed":1221,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 14, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"umohpBN2OM94"},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # hidden shape == (batch_size, hidden size)\n","    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","    # we are doing this to perform addition to calculate the score\n","    hidden_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(values) + self.W2(hidden_with_time_axis)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k534zTHiDjQU","outputId":"202e0fde-a8c3-4cad-c7ce-2094a6dd9022","executionInfo":{"status":"ok","timestamp":1581090678214,"user_tz":-210,"elapsed":22992,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 14, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJ_B3mhW3jFk"},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.vocab_size = vocab_size\n","\n","    # self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    # x = self.embedding(x)\n","    \n","    \n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), tf.expand_dims(x, 1)], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5UY8wko3jFp","outputId":"0b340da3-4b10-4ed1-97c8-b84464a26c88","executionInfo":{"status":"ok","timestamp":1581090719900,"user_tz":-210,"elapsed":617,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 4559)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_ch_71VbIRfK"},"source":["## Define the optimizer and the loss function"]},{"cell_type":"code","metadata":{"id":"WmTHr5iV3jFr"},"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMVWzzsfNl4e"},"source":["## Checkpoints (Object-based saving)"]},{"cell_type":"code","metadata":{"id":"Zj8bXQTgNwrF"},"source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC9ArXSsVfqn"},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddefjBMa3jF0"},"source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mU3Ce8M6I3rz"},"source":["## Translate\n","\n","* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n","* Stop predicting when the model predicts the *end token*.\n","* And store the *attention weights for every time step*.\n","\n","Note: The encoder output is calculated only once for one input."]},{"cell_type":"code","metadata":{"id":"EbQpyYs13jF_"},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # storing the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5hQWlbN3jGF"},"source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpNAuxNl4Jk4"},"source":["import nltk\n","def translate(sentence,true_translate):\n","  result, sentence, attention_plot = evaluate(sentence)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","  print(\"BLEU : \", nltk.translate.bleu_score.sentence_bleu([result.split(' ')],true_translate))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dL8a5-Hf4JlV","outputId":"5194fb18-cb8d-4d74-8b38-5a9adab70bbb","executionInfo":{"status":"ok","timestamp":1581133123145,"user_tz":-210,"elapsed":1064,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f044e336a58>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"GT2Uoumn4Jlj","outputId":"209014a8-ad9d-45fd-f127-de384cef7b9f","executionInfo":{"status":"ok","timestamp":1581133123855,"user_tz":-210,"elapsed":1125,"user":{"displayName":"hemen zandi","photoUrl":"","userId":"07645378304220230421"}},"colab":{"base_uri":"https://localhost:8080/","height":715}},"source":["translate(u\"Es ist wirklich kalt hier.\",\"It's really cold here.\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: <start> es ist wirklich kalt hier . <end>\n","Predicted translation: it s really cold . <end> \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAnUAAAI5CAYAAADHbcxDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU :  0.5491004867761125\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UDTQlR314Jlx"},"source":["translate(u'das ist mein Leben.',\"that is my life.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-ihu3Cc4Jl7"},"source":["translate(u\"Sind sie noch zu Hause?\",\"Are you still at home?\")"],"execution_count":null,"outputs":[]}]}